{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf04605d",
   "metadata": {},
   "source": [
    "# SCRAP B3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0881a419",
   "metadata": {},
   "source": [
    "Pipeline Batch Bovespa (entrega obrigatória):\n",
    "\n",
    "- ✅ Requisito 1: scrap de dados do site da B3 com dados do pregão.\n",
    "- ⬜ Requisito 2: os dados brutos devem ser ingeridos no s3 em formato parquet com partição diária.\n",
    "- ⬜ Requisito 3: o bucket deve acionar uma lambda, que por sua vez irá chamar o job de ETL no glue.\n",
    "- ⬜ Requisito 4: a lambda pode ser em qualquer linguagem. Ela apenas deverá iniciar o job Glue.\n",
    "- ⬜ Requisito 5: o job Glue deve ser feito no modo visual. Este job deve conter as seguintes transformações obrigatórias:\n",
    "  - A: agrupamento numérico, sumarização, contagem ou soma.\n",
    "  - B: renomear duas colunas existentes além das de agrupamento.\n",
    "  - C: realizar um cálculo com campos de data, exemplo, poder ser duração, comparação, diferença entre datas.\n",
    "- ⬜ Requisito 6: os dados refinados no job glue devem ser salvos no formato parquet em uma pasta chamada refined, particionado por data e pelo nome ou abreviação da ação do pregão.\n",
    "- ⬜ Requisito 7: o job Glue deve automaticamente catalogar o dado no Glue Catalog e criar uma tabela no banco de dados default do Glue Catalog.\n",
    "- ⬜ Requisito 8: os dados devem estar disponíveis e legíveis no Athena.\n",
    "- ⬜ Requisito 9: é opcional construir um notebook no Athena para montar uma visualização gráfica dos dados ingeridos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838bc154",
   "metadata": {},
   "source": [
    "### LINK OBRIGATÓRIO:\n",
    "#### https://sistemaswebb3-listados.b3.com.br/indexPage/day/IBOV?language=pt-br"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e258c0f6",
   "metadata": {},
   "source": [
    "# Requisito 1: scrap de dados do site da B3 com dados do pregão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e97b4407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recebidos 84 registros.\n",
      "[\n",
      "  {\n",
      "    \"segment\": \"Bens Indls / Máqs e Equips\",\n",
      "    \"cod\": \"WEGE3\",\n",
      "    \"asset\": \"WEG\",\n",
      "    \"type\": \"ON  EJ  NM\",\n",
      "    \"part\": \"2,905\",\n",
      "    \"partAcum\": \"2,905\",\n",
      "    \"theoricalQty\": \"1.482.105.837\"\n",
      "  },\n",
      "  {\n",
      "    \"segment\": \"Bens Indls / Mat Transporte\",\n",
      "    \"cod\": \"EMBR3\",\n",
      "    \"asset\": \"EMBRAER\",\n",
      "    \"type\": \"ON      NM\",\n",
      "    \"part\": \"2,513\",\n",
      "    \"partAcum\": \"2,751\",\n",
      "    \"theoricalQty\": \"734.631.701\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Payload atualizado para consulta por setor com pageSize=20 e segment=2 (exemplo)\n",
    "payload = \"eyJsYW5ndWFnZSI6InB0LWJyIiwicGFnZU51bWJlciI6MSwicGFnZVNpemUiOjEyMCwiaW5kZXgiOiJJQk9WIiwic2VnbWVudCI6IjIifQ==\"\n",
    "url = f\"https://sistemaswebb3-listados.b3.com.br/indexProxy/indexCall/GetPortfolioDay/{payload}\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\",\n",
    "    \"Accept\": \"application/json\"\n",
    "}\n",
    "\n",
    "resp = requests.get(url, headers=headers)\n",
    "resp.raise_for_status()\n",
    "data = resp.json()\n",
    "\n",
    "registros = data.get(\"results\") or data\n",
    "if isinstance(registros, dict):\n",
    "    # tentar pegar lista dentro do dict\n",
    "    registros = next((v for v in registros.values() if isinstance(v, list)), [data])\n",
    "\n",
    "print(f\"Recebidos {len(registros)} registros.\")\n",
    "print(json.dumps(registros[:2], ensure_ascii=False, indent=2))  # imprime só os 2 primeiros para exemplo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c6ebff",
   "metadata": {},
   "source": [
    "# Requisito 2: os dados brutos devem ser ingeridos no s3 em formato parquet com partição diária."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b49159",
   "metadata": {},
   "source": [
    "### GERAR PARQUET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d6e3b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo salvo como: .parquet/dados_ibov_2025-06-21.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Data do pregão\n",
    "data_pregao = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def process_registro(registro):\n",
    "    # Corrigir campo 'segment'\n",
    "    raw_segment = registro.get('segment', '')\n",
    "    raw_segment = raw_segment.strip()\n",
    "    setores = [s.strip() for s in raw_segment.split('/') if s.strip()] if raw_segment else []\n",
    "\n",
    "    # Corrigir campo 'type'\n",
    "    raw_type = registro.get('type', '')\n",
    "    raw_type = raw_type.strip()\n",
    "    tipos = [t.strip() for t in raw_type.split() if t.strip()] if raw_type else []\n",
    "\n",
    "    # Adicionar listas e data\n",
    "    registro['segment_list'] = setores\n",
    "    registro['type_list'] = tipos\n",
    "    registro['data_pregao'] = data_pregao\n",
    "    return registro\n",
    "\n",
    "# Processar\n",
    "registros_processados = [process_registro(r) for r in registros]\n",
    "\n",
    "# Criar DataFrame\n",
    "df = pd.DataFrame(registros_processados)\n",
    "\n",
    "# Nome do arquivo com data\n",
    "output_dir = \".parquet\"\n",
    "filename = f\"{output_dir}/dados_ibov_{data_pregao}.parquet\"\n",
    "\n",
    "# Criar a pasta se não existir\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Salvar\n",
    "df.to_parquet(filename, engine=\"pyarrow\", index=False)\n",
    "print(f\"Arquivo salvo como: {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf43520",
   "metadata": {},
   "source": [
    "### LER PARQUET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd893b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abrindo: dados_ibov_2025-06-21.parquet\n",
      "                       segment    cod      asset        type   part partAcum  \\\n",
      "0   Bens Indls / Máqs e Equips  WEGE3        WEG  ON  EJ  NM  2,905    2,905   \n",
      "1  Bens Indls / Mat Transporte  EMBR3    EMBRAER  ON      NM  2,513    2,751   \n",
      "2  Bens Indls / Mat Transporte  POMO4  MARCOPOLO  PN      N2  0,238    2,751   \n",
      "3        Bens Indls/Transporte  MOTV3  MOTIVA SA  ON      NM  0,632    1,927   \n",
      "4        Bens Indls/Transporte  RAIL3  RUMO S.A.  ON  ED  NM  1,031    1,927   \n",
      "\n",
      "    theoricalQty                  segment_list     type_list data_pregao  \n",
      "0  1.482.105.837   [Bens Indls, Máqs e Equips]  [ON, EJ, NM]  2025-06-21  \n",
      "1    734.631.701  [Bens Indls, Mat Transporte]      [ON, NM]  2025-06-21  \n",
      "2    666.378.439  [Bens Indls, Mat Transporte]      [PN, N2]  2025-06-21  \n",
      "3    991.920.937      [Bens Indls, Transporte]      [ON, NM]  2025-06-21  \n",
      "4  1.216.914.397      [Bens Indls, Transporte]  [ON, ED, NM]  2025-06-21  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# Diretório onde os arquivos estão\n",
    "caminho = Path('.')  # ou Path('caminho/da/pasta') se estiver em outro lugar\n",
    "\n",
    "# Procurar arquivos parquet com nome no formato esperado\n",
    "arquivos = list(caminho.glob(\".parquet/dados_ibov_*.parquet\"))\n",
    "\n",
    "# Extrair data do nome e ordenar\n",
    "def extrair_data(arquivo):\n",
    "    match = re.search(r'dados_ibov_(\\d{4}-\\d{2}-\\d{2})\\.parquet', arquivo.name)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return '0000-00-00'  # fallback para ordenar corretamente\n",
    "\n",
    "# Ordenar do mais recente para o mais antigo\n",
    "arquivos_ordenados = sorted(arquivos, key=extrair_data, reverse=True)\n",
    "\n",
    "# Verifica se há arquivos\n",
    "if arquivos_ordenados:\n",
    "    arquivo_mais_recente = arquivos_ordenados[0]\n",
    "    df = pd.read_parquet(arquivo_mais_recente)\n",
    "    print(f\"Abrindo: {arquivo_mais_recente.name}\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"Nenhum arquivo 'dados_ibov_*.parquet' encontrado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cab5bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
